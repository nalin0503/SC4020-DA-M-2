{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>category</th>\n",
       "      <th>POI_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39059</th>\n",
       "      <td>187</td>\n",
       "      <td>200</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39060</th>\n",
       "      <td>187</td>\n",
       "      <td>200</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39061</th>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39062</th>\n",
       "      <td>188</td>\n",
       "      <td>200</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39063</th>\n",
       "      <td>189</td>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39064 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x    y  category  POI_count\n",
       "0        1   35        48          1\n",
       "1        1   38        48          1\n",
       "2        1   45        48          1\n",
       "3        1   45        47          1\n",
       "4        1  108        46          1\n",
       "...    ...  ...       ...        ...\n",
       "39059  187  200        81          1\n",
       "39060  187  200        48          1\n",
       "39061  188  199        63          1\n",
       "39062  188  200        73          1\n",
       "39063  189  200        75          1\n",
       "\n",
       "[39064 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path, sample_size=None):\n",
    "    data = pd.read_csv(file_path)\n",
    "    if sample_size is not None:\n",
    "        data = data.sample(sample_size, random_state=42)\n",
    "    # in future, we will add more data preprocessing steps here\n",
    "    return data\n",
    "\n",
    "\n",
    "cityc = load_data('POIdata_cityC.csv')\n",
    "cityc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The headers of city C are: x, y, category, POI_count\n",
    "\n",
    "baskets = []\n",
    "\n",
    "for city in 'A','B', 'C', 'D':\n",
    "    raw = load_data(f'POIdata_city{city}.csv')\n",
    "    groupd = raw.groupby(['x', 'y'], as_index=False).agg({'category': list})\n",
    "    baskets.extend(groupd['category'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic minimum support threshold (scaled): 2289.92\n",
      "Generated 48 frequent 1-itemsets\n",
      "Generated 563 frequent 2-itemsets\n",
      "Generated 2917 frequent 3-itemsets\n",
      "Generated 7263 frequent 4-itemsets\n",
      "Generated 9563 frequent 5-itemsets\n",
      "Generated 6962 frequent 6-itemsets\n",
      "Generated 2708 frequent 7-itemsets\n",
      "Generated 483 frequent 8-itemsets\n",
      "Generated 30 frequent 9-itemsets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_freq_itemsets(binary_matrix, unique_items):\n",
    "    num_items = len(unique_items)\n",
    "    freq_itemsets = {}\n",
    "\n",
    "    # Calculate item counts for 1-itemsets\n",
    "    item_counts = np.sum(binary_matrix, axis=0)\n",
    "    \n",
    "    # Dynamically calculate minimum support as the average support of 1-itemsets\n",
    "    minsup = np.mean(item_counts)\n",
    "    scaled_minsup = minsup * 0.5  # Adjust with a scaling factor to lower minsup\n",
    "    print(f\"Dynamic minimum support threshold (scaled): {scaled_minsup:.2f}\")\n",
    "    \n",
    "    # Generate frequent 1-itemsets\n",
    "    freq_1 = np.where(item_counts >= scaled_minsup)[0]\n",
    "    freq_itemsets[1] = [frozenset([unique_items[i]]) for i in freq_1]\n",
    "    print(f\"Generated {len(freq_itemsets[1])} frequent 1-itemsets\")\n",
    "\n",
    "    k = 2\n",
    "    while True:\n",
    "        prev_freq = freq_itemsets.get(k - 1, [])\n",
    "        if not prev_freq:\n",
    "            break\n",
    "\n",
    "        # Generate candidate k-itemsets\n",
    "        candidates = []\n",
    "        len_prev = len(prev_freq)\n",
    "        for i in range(len_prev):\n",
    "            for j in range(i + 1, len_prev):\n",
    "                union = prev_freq[i].union(prev_freq[j])\n",
    "                if len(union) == k:\n",
    "                    # Prune step: check if all (k-1)-subsets are frequent\n",
    "                    subsets = [union - frozenset([item]) for item in union]\n",
    "                    if all(subset in freq_itemsets[k - 1] for subset in subsets):\n",
    "                        candidates.append(union)\n",
    "\n",
    "        # Remove duplicates\n",
    "        candidates = list(set(candidates))\n",
    "        if not candidates:\n",
    "            break\n",
    "\n",
    "        # Convert candidates to binary mask\n",
    "        candidate_masks = np.zeros((len(candidates), num_items), dtype=int)\n",
    "        for idx, candidate in enumerate(candidates):\n",
    "            for item in candidate:\n",
    "                candidate_masks[idx, item_index[item]] = 1\n",
    "\n",
    "        # Optimized Frequency Counting using Matrix Multiplication\n",
    "        dot_product = binary_matrix @ candidate_masks.T  # Shape: (num_baskets, num_candidates)\n",
    "        subset_check = dot_product == k  # Boolean array\n",
    "        freq_counts = np.sum(subset_check, axis=0)\n",
    "\n",
    "        # Select candidates that meet or exceed scaled minsup\n",
    "        freq_candidates_indices = np.where(freq_counts >= scaled_minsup)[0]\n",
    "\n",
    "        # Store frequent k-itemsets\n",
    "        freq_k = [frozenset([unique_items[idx] for idx in np.where(candidate_masks[i])[0]]) \n",
    "                  for i in freq_candidates_indices]\n",
    "        if freq_k:\n",
    "            freq_itemsets[k] = freq_k\n",
    "            print(f\"Generated {len(freq_k)} frequent {k}-itemsets\")\n",
    "            k += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return freq_itemsets\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example binary matrix and unique items\n",
    "    \n",
    "    unique_items = sorted(set(item for basket in baskets for item in basket))\n",
    "    item_index = {item: idx for idx, item in enumerate(unique_items)}\n",
    "    \n",
    "    # Create binary matrix\n",
    "    binary_matrix = np.zeros((len(baskets), len(unique_items)), dtype=np.bool_)\n",
    "    for i, basket in enumerate(baskets):\n",
    "        for item in basket:\n",
    "            binary_matrix[i, item_index[item]] = 1\n",
    "    \n",
    "    # Apriori Settings\n",
    "    minsup = 2000  # Minimum support threshold\n",
    "    \n",
    "    # Generate frequent itemsets\n",
    "    freq_itemsets = generate_freq_itemsets(binary_matrix, unique_items)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def generate_association_rules(freq_itemsets, binary_matrix, unique_items, minsup, minconf):\n",
    "    \"\"\"\n",
    "    Generate association rules from frequent itemsets.\n",
    "\n",
    "    Parameters:\n",
    "    - freq_itemsets: dict, frequent itemsets with their sizes as keys\n",
    "    - binary_matrix: np.ndarray, binary representation of baskets\n",
    "    - unique_items: list, sorted list of unique items\n",
    "    - minsup: int, minimum support threshold\n",
    "    - minconf: float, minimum confidence threshold (e.g., 0.7 for 70%)\n",
    "\n",
    "    Returns:\n",
    "    - rules: list of tuples, each tuple contains (antecedent, consequent, support, confidence)\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    item_index = {item: idx for idx, item in enumerate(unique_items)}\n",
    "    \n",
    "    # Precompute support counts for all frequent itemsets\n",
    "    support_counts = {}\n",
    "    for k, itemsets in freq_itemsets.items():\n",
    "        for itemset in itemsets:\n",
    "            support_counts[itemset] = np.sum(\n",
    "                np.all(binary_matrix[:, list(item_index[item] for item in itemset)] == 1, axis=1)\n",
    "            )\n",
    "    \n",
    "    for k in freq_itemsets:\n",
    "        if k < 2:\n",
    "            continue  # Need at least 2 items to form a rule\n",
    "        print(f\"Generating rules from {k}-itemsets\")\n",
    "        for itemset in freq_itemsets[k]:\n",
    "            # Generate all non-empty proper subsets of the itemset\n",
    "            subsets = list(chain.from_iterable(combinations(itemset, r) for r in range(1, len(itemset))))\n",
    "            for antecedent in subsets:\n",
    "                antecedent = frozenset(antecedent)\n",
    "                consequent = itemset - antecedent\n",
    "                if not consequent:\n",
    "                    continue\n",
    "                # Calculate support and confidence\n",
    "                support = support_counts[itemset]\n",
    "                antecedent_support = support_counts.get(antecedent, 0)\n",
    "                if antecedent_support == 0:\n",
    "                    continue\n",
    "                confidence = support / antecedent_support\n",
    "                if confidence >= minconf:\n",
    "                    rules.append((set(antecedent), set(consequent), support, confidence))\n",
    "    \n",
    "    return rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rules from 2-itemsets\n",
      "Generating rules from 3-itemsets\n",
      "Generating rules from 4-itemsets\n",
      "Generating rules from 5-itemsets\n",
      "Generating rules from 6-itemsets\n",
      "Generating rules from 7-itemsets\n",
      "Generating rules from 8-itemsets\n",
      "Generating rules from 9-itemsets\n"
     ]
    }
   ],
   "source": [
    "rus = generate_association_rules(freq_itemsets, binary_matrix, unique_items, minsup, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check generated frequent itemsets\n",
    "#print(\"Frequent Itemsets:\", freq_itemsets)\n",
    "\n",
    "# Check rule generation\n",
    "#for k, itemsets in freq_itemsets.items():\n",
    "#    print(f\"Generating rules from {k}-itemsets\")\n",
    "#    for itemset in itemsets:\n",
    "#        print(\"Itemset:\", itemset)\n",
    "\n",
    "# Check individual rules\n",
    "#print(\"Generated Rules:\")\n",
    "#for rule in rus:\n",
    "#    print(rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for rule in rus:\n",
    "#    antecedent, cent, support,confidence = rule\n",
    "#    confidence_str = f\"{confidence:.2f}\" if confidence is not None else \"N/A\"\n",
    "#    print(f\"Rule: {antecedent} -> {consequent} (Support: {support}, Confidence: {confidence:.2f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
